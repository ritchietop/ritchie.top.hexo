---
title: 【论文小品】Deep neural networks for YouTube recommendations
mathjax: true
toc: false
comments: true
date: 2019-09-15 09:14:17
categories: paper
tags: dnn recommendation
---

[论文地址](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45530.pdf)

这篇论文主要是讲深度学习模型在YouTube视频推荐系统中的应用，包括**候选集生成模型**和**排序模型**两部分。

<!--more-->

# 系统概览

{% asset_img system_overview.png 系统概览 %}

系统主要由候选集生成和排序两个步骤组成。候选集生成解决的是系统无法对海量视频进行全覆盖的在线实时打分。排序解决的是推荐结果呈现给用户的排列顺序。

整个系统的基本流程是这样的：

1. 候选集生成模型利用用户的历史行为和访问时的上下文数据，从海量的视频库中检索出一个较小的视频库子集。（离线粗筛）
2. 排序模型整合多种渠道的视频库子集，利用用户的历史行为、访问时的上下文数据、视频特征等，完成对视频的打分排序。并选择TopN个视频推荐给用户。（在线细筛）

通过该系统，我们可以实现从超大规模的视频库中，筛选出个性化的推荐结果呈现给用户。

> 注意：离线训练的结果和线上的表现不一定总是相关。所以，模型最终的表现还需要在线上进行A/B测试

# 候选集生成模型

候选集生成模型完成了从海量的视频库中，粗筛出几百个和用户最相关的候选视频。

## 模型输出

模型最终得到的是用户、视频在同一个向量空间的投影。即，得到具有相同维度的、能够进行点积计算的用户和视频向量。

## 目标问题

视频推荐问题，我们可以将其转换成分类问题。这里我们将每个视频作为一个类别，则视频推荐问题可以这样描述：

> 在给定用户$U$和上下文$C$的情况下，预测在时间$t$，类别$w_t$为视频$i$的概率

$$P(w_t=i|U,C) = \dfrac {e^{v_i u}} {\sum_{j \in V} {e^{v_i u}}}$$

上面是多分类中用到的SoftMax公式，这里 $v_i \in R^N$，$u \in R^N$，分别表示视频和用户的嵌入向量。接下来的训练任务就是得到这两个嵌入向量。

> 需要注意的是，在计算中是将用户和视频的向量进行了点积。

### softmax loss

交叉熵：

$$Loss = - \sum_{i \in V}^{|V|} {y_i} \log {P(y=y_i)}$$

$V$表示类别空间，$y_i$是实际的概率值，所以她的取值只有0和1。如果是单分类问题，每条样本只对应一个类别，就会只有一个$y_i$的值为1。

$P(y=y_i)$是模型预测类别为$y_i$的概率值，所以，取值介于[0,1]。具体计算公式如下（就是softMax公式）：

$$P(y=y_i) = \dfrac {e^{v_i u}} { \sum_{j \in V} { e^{v_j u}}}$$

通过上面的公式可以发现，为了计算一条样本的loss，我们需要对$V$中的每个类别都计算一次softMax。当$|V|$的值很大的时候，样本loss的计算成本会很高。

**论文中的目标问题就是一个类别空间超级大的多分类问题。**

### 负采样

为了加快模型训练，论文中采用了负采样的方法。负采样是一种候选采样方法。

#### 应用场景描述

假设我们有这样一个问题，给定一个样本集，其中每个样本由$(x_i, T_i)$，其中$x_i$是输入特征，$T_i$是一个target小集合，满足$T \subset L$, $|T| << |L|$。我们的目标是学习一个$F(x, y)$，使得给定一个$x$，我们可以预测出类别$y$为正的可能性。

如果我们使用正常的softmax方法，那么在计算每一个sample时，我们都需要遍历整个集合，对每一个可能的类别都计算一次。在类别集合特别大的情况下，这种方法的计算成本很高。

#### 候选采样

在训练每个样本$(x_i, T_i)$时，我们只需要$F(x, y)$在一个小的候选类别集合$C_i$进行评估。其中，$C_i = T_i \bigcup S_i$。这里的$S_i$是基于指定的随机采样方法获得的一个类别子集，其中，$S_i \subset L$

上述随机采样得到$S_i$的过程，是否依赖$x_i$和$T_i$不做限制。

> 论文中采用的负采样方法就是从视频库中随机选择一些视频作为负例标签

## 模型结构

{% asset_img model_architecture.png 候选生成模型 %}

### 样本示例

> 用户观察视频列表，用户历史搜索记录列表，用户性别，用户年龄，用户地域，行为访问设备，用户登录状态，样本年龄，视频ID

**用户观看视频列表**：对视频ID进行嵌入维度为$N_{video}$的Embedding处理，然后将$K_{video}$个视频列表合并成一个$1 * N_{video}$维的向量

**用户历史搜索记录列表**：把历史搜索记录进行分词，利用word2vec转换成维度为$N_{query}$的词向量，然后将$K_{query}$个搜索词合并成一个$1 * N_{query}$维的向量

**用户性别、用户年龄、用户地域、行为访问设备、用户登录状态**：离散特征可以使用onehot，或者Embedding方式进行转换

**样本年龄**：连续特征可以直接输入到模型中，也可以通过Embedding的方式处理

**视频ID**：进行Embedding处理

> ### 关于样本年龄的说明
> 
> 样本年龄指的是，训练样本的触发时间距离模型训练时的时间间隔。
> 
> 在视频领域，通常来说，用户更倾向于点击新上传的视频。而利用用户历史行为的训练，模型通常会倾向于推荐已观看的旧视频。
>
> 基于这个特点，论文中将样本年龄加入到了模型中，使得模型可以学习到用户行为的时序特征。
> 
> {% asset_img video_upload_time.png 样本年龄 %}
> 
> 加入**样本年龄**之后，整个预测的结果就和预期的用户点击行为分布基本一致了。
>
> 在模型预测时，会将样本年龄设置为0或者一个很小的负数，表示模型在对当前的样本进行预测。
> 
> ### 关于用户观看视频列表和用户历史搜索记录列表的合并
> 
> 将多个视频的嵌入向量合并成一个向量，可以采用sum、mean、sqrtn、attention等方法
> 
> ### 关于视频ID的嵌入向量的说明
> 
> 模型中有两个地方都使用了视频ID的嵌入向量，分别是计算用户观看视频列表、模型输出时计算用户向量和视频向量的点积
> 
> 经过实际的对比，这两个地方进行嵌入向量的共享比分别做嵌入的实际效果要好。推荐使用共享视频ID嵌入向量的实现方法。
> 

### 模型输入

将上面各个向量（除了视频ID）进行连接操作（concat），得到一个1 * N 维的向量。如果是多批次训练，会得到一个batch_size * 1 * N的向量。这里的N是上面所有各个特征维度的和。

### 隐含层

论文中采用塔式的层结构（具体可见参加上面的模型结果图），对包含0、1、2、3、4层隐含层进行实验，分别对应0、256、512、1024、2048个隐藏单元。下图展示了不同情况下的实验结果：

{% asset_img hidden_network.png 隐含层 %}

总的来说，隐含层超过3层，对模型效果的提升贡献就不大了。所以，推荐使用3层隐含层。

### 训练数据的处理

论文中对训练过程不同的数据处理方式进行了尝试，给出了一些值得借鉴的训练数据处理建议。

- 选择更广泛的训练数据，不仅仅只包含推荐的行为数据
    - 发现新内容，避免推荐结果被过分利用（Exploration & Exploitation）
- 为每个用户生成固定数据的训练数据
    - 避免loss被少数特别活跃的用户影响
- 去除视频观看的序列特征
    - 论文中给出的解释是：可能模型没有对负反馈进行很好的建模
- 不对称浏览行为
    - 利用上下文预测中间行为（下面的更好）
        - 很多协同过滤系统其实就是基于上下文预测中间行为
    - 利用上文信息预测接未来行为（这个更好）

{% asset_img behavior.png 不对称浏览 %}

> ### Exploration & Exploitation
> 
> 探索与利用问题是强化学习中一个基础概念
> 
> #### 场景举例
> 
> 公司附近有很多餐馆，我们已经尝试过几家，并有了一个基本的评价。如果我们想得到最大化美食带来的体验，我们应该如何选择餐馆？
> 
> **探索**：我们随机的选择餐馆，以得到对更多餐馆更精确的评价。如果餐馆数量特别多，这样需要大量的尝试，效率太低。
> **利用**：我们只选择已经掌握评价信息的餐馆。最大体验被限制，如果体验次数太多，会带来体验下降的风险。
> 
> 折中的策略是：大部分时间利用（exploitation），同时以一定的概率探索（exploration），这就是探索-利用平衡。
> 

### 最近邻（NN)与近似最近邻（ANN）

候选集生成模型最终得到的是用户和视频ID的在同一空间下的嵌入向量。接下来，我们就需要对指定用户，计算与之最为相似的视频ID。即，求解用户向量的最近邻问题。

通常来讲，在向量维度不高、计算复杂度尚可接受的情况下，可以选择精确检索方法。如果维度过大，精确检索的计算花费已经到了让人无法容忍的地步，就需要选择近似检索的方法，以牺牲少许的精度，来换取可观的效率提升。

#### 精确检索

- KD树

构建过程：
输入：向量集合
1. 如果向量集合为空，返回空的KD树
2. 节点生成过程：
    1. 确定Split域

- R树
- M树

#### 近似检索

- 局部敏感哈希（LSH）
- 乘积量化（PQ）

# 排序模型

排序模型是在候选生成模型的基础上，实现对粗筛之后的候选视频的精准排序。在模型设计上，排序模型采用了和候选生成模型类似的模型架构设计，只是在模型的输入层和输出层进行了修改。

## 模型结构

{% asset_img ranking.png 排序模型 %}

## 模型输入

不同于候选生成模型需要对海量的视频进行处理计算，排序模型需要处理的只是经过一系列粗筛之后得到的小规模视频集合。所以，排序模型可以使用更加复杂的特征作为模型的输入，以期达到更为精准的排序目的。

论文中在排序模型的输入层增加了用户语言、视频语言、视频最后观看时间等特征。

### 关于输入特征处理的一些技巧

> 对同源特征使用嵌入向量的共享，实现模型训练的加速和效果提升

例如用户语言和视频语言、目标视频ID和历史观看视频ID列表这种，属于同源特征

> 连续特征可以增加对特征的开方、平方，以挖掘特征的非线性关系

## 模型输出

不同于候选生成模型的softmax输出，排序模型在模型训练和线上模型预测时，都使用

### 训练侧输出

排序模型使用加权的逻辑回归（weighted logistics）作为模型输出

$$ weighted_loss = 1 / N * \sum^{N}_{i=0} {w_i * e ^ {u * v}} $$

### 预测侧输出

预测侧的输出根据训练侧推导而来

$$ loss = 

### 关于模型输出变更的解释


# 小米生活选品模型

{% asset_img user_item_model.png 用户商品模型 %}

